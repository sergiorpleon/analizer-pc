# üîß Soluci√≥n: Error "model llama3 not found"

## ‚ùå Error

```
Error al generar embedding: Client error: `POST http://ollama:11434/api/embeddings` 
resulted in a `404 Not Found` response: 
{"error":"model \"llama3\" not found, try pulling it first"}
```

## üéØ Causa

El modelo `llama3` no est√° descargado en el contenedor de Ollama.

## ‚úÖ Soluci√≥n

### Opci√≥n 1: Descargar el Modelo (Recomendado)

```bash
# Descargar llama3 (4.7 GB - tarda unos minutos)
docker-compose exec ollama ollama pull llama3
```

**Espera a que termine la descarga.** Ver√°s algo como:
```
pulling manifest
pulling 6a0746a1ec1a: 100%
pulling 4fa551d4f938: 100%
pulling 8ab4849b038c: 100%
...
success
```

### Opci√≥n 2: Usar un Modelo M√°s Peque√±o

Si `llama3` es muy grande, puedes usar un modelo m√°s peque√±o:

#### 1. Descargar un modelo alternativo

```bash
# Llama3.2 (2 GB - m√°s peque√±o)
docker-compose exec ollama ollama pull llama3.2

# O Gemma 2B (1.4 GB - a√∫n m√°s peque√±o)
docker-compose exec ollama ollama pull gemma:2b
```

#### 2. Actualizar la configuraci√≥n

Edita **`config/config.php`**:

```php
'ollama' => [
    'url' => 'http://ollama:11434',
    'model' => 'llama3.2',  // o 'gemma:2b'
    'embedding_size' => 4096
],
```

#### 3. Reiniciar la aplicaci√≥n

```bash
docker-compose restart app
```

### Opci√≥n 3: Verificar Modelos Disponibles

```bash
# Ver qu√© modelos est√°n instalados
docker-compose exec ollama ollama list
```

## üîç Verificar que Funciona

Despu√©s de descargar el modelo:

1. **Accede a la p√°gina principal:**
   ```
   http://localhost:8000/
   ```

2. **Deber√≠as ver:**
   ```
   ‚úÖ Ollama responde: [mensaje de saludo]
   ```

3. **Prueba el buscador:**
   ```
   http://localhost:8000/search
   ```

## üìä Modelos Disponibles y Tama√±os

| Modelo | Tama√±o | Velocidad | Calidad |
|--------|--------|-----------|---------|
| `llama3` | 4.7 GB | Media | Alta |
| `llama3.2` | 2.0 GB | R√°pida | Buena |
| `llama3.2:1b` | 1.3 GB | Muy r√°pida | Media |
| `gemma:2b` | 1.4 GB | Muy r√°pida | Media |
| `phi3` | 2.3 GB | R√°pida | Buena |

## üöÄ Comandos √ötiles de Ollama

```bash
# Listar modelos instalados
docker-compose exec ollama ollama list

# Descargar un modelo
docker-compose exec ollama ollama pull <modelo>

# Eliminar un modelo
docker-compose exec ollama ollama rm <modelo>

# Probar un modelo
docker-compose exec ollama ollama run llama3 "Hola, ¬øc√≥mo est√°s?"

# Ver logs de Ollama
docker-compose logs ollama
```

## üîÑ Proceso de Descarga

La descarga de `llama3` puede tardar:
- **Conexi√≥n r√°pida (100 Mbps)**: 5-10 minutos
- **Conexi√≥n media (50 Mbps)**: 10-15 minutos
- **Conexi√≥n lenta (10 Mbps)**: 30-60 minutos

**Progreso t√≠pico:**
```
pulling manifest
pulling 6a0746a1ec1a:  10% ‚ñï‚ñà‚ñà        ‚ñè 470 MB/4.7 GB
pulling 6a0746a1ec1a:  50% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñè 2.3 GB/4.7 GB
pulling 6a0746a1ec1a: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 4.7 GB/4.7 GB
pulling 4fa551d4f938: 100%
pulling 8ab4849b038c: 100%
success
```

## ‚ö†Ô∏è Problemas Comunes

### 1. "Error: connection refused"

**Soluci√≥n:**
```bash
# Verificar que Ollama est√© corriendo
docker-compose ps ollama

# Si no est√° corriendo, iniciarlo
docker-compose up -d ollama
```

### 2. "Error: out of disk space"

**Soluci√≥n:**
- Libera espacio en disco (necesitas ~5 GB libres)
- O usa un modelo m√°s peque√±o (ver Opci√≥n 2)

### 3. Descarga muy lenta

**Soluci√≥n:**
```bash
# Detener y reiniciar la descarga
docker-compose exec ollama ollama pull llama3
```

## üìù Resumen

1. ‚úÖ **Ejecuta:** `docker-compose exec ollama ollama pull llama3`
2. ‚è≥ **Espera** a que termine la descarga (5-15 minutos)
3. üîÑ **Recarga** la p√°gina: `http://localhost:8000/`
4. ‚úÖ **Verifica** que Ollama responde correctamente

---

**Estado actual:** El modelo se est√° descargando. Espera a que termine y luego recarga la p√°gina.
